{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values...\n",
      "Name                         0\n",
      "Age                          0\n",
      "Gender                       0\n",
      "BMI                          0\n",
      "Smoking Status               0\n",
      "Region                       0\n",
      "Diabetes                     0\n",
      "Hypertension                 0\n",
      "Heart Disease                0\n",
      "Cancer History               0\n",
      "Stroke                       0\n",
      "Liver Disease                0\n",
      "Kidney Disease               0\n",
      "COPD                         0\n",
      "TB                           0\n",
      "HIV/AIDS                     0\n",
      "Alcohol Consumption          0\n",
      "Exercise Frequency           0\n",
      "Diet Type                    0\n",
      "Stress Level                 0\n",
      "Medical History Score        0\n",
      "Annual Income                0\n",
      "Employment Type              0\n",
      "Credit Score                 0\n",
      "Savings Amount               0\n",
      "Number of Dependents         0\n",
      "Previous Insurance Claims    0\n",
      "Policy Type                  0\n",
      "Policy Renewal Status        0\n",
      "Hospital Visits Per Year     0\n",
      "Medication Costs Per Year    0\n",
      "Insurance Cost               0\n",
      "BMI Smoker                   0\n",
      "Income Dependents            0\n",
      "dtype: int64\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret loss identifier: huber_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 63\u001b[0m\n\u001b[1;32m     58\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m     59\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuber_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     60\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# ‚úÖ 1Ô∏è‚É£2Ô∏è‚É£ Train Model\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# ‚úÖ 1Ô∏è‚É£3Ô∏è‚É£ Plot Training Loss\u001b[39;00m\n\u001b[1;32m     72\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/keras/src/losses/__init__.py:207\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret loss identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret loss identifier: huber_loss"
     ]
    }
   ],
   "source": [
    "# ‚úÖ 1Ô∏è‚É£ Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ‚úÖ 2Ô∏è‚É£ Disable GPU (If CUDA Errors Occur)\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# ‚úÖ 3Ô∏è‚É£ Load Dataset\n",
    "df = pd.read_csv(\"insurance_cleaned.csv\")  # Ensure this file exists in the correct directory\n",
    "\n",
    "# ‚úÖ 4Ô∏è‚É£ Check for Missing Values & Handle Them\n",
    "print(\"Checking for missing values...\")\n",
    "print(df.isnull().sum())  # Show missing values per column\n",
    "\n",
    "# Fill missing numerical values with median\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# ‚úÖ 5Ô∏è‚É£ Fix Log Transformation Issues\n",
    "# Select numerical features prone to skewness\n",
    "skewed_features = ['Savings Amount', 'BMI']  \n",
    "for feature in skewed_features:\n",
    "    df[feature] = np.log1p(df[feature].clip(lower=0))  # Avoid log(negative)\n",
    "\n",
    "# ‚úÖ 6Ô∏è‚É£ Feature Engineering\n",
    "df['BMI_Smoker_Interaction'] = df['BMI'] * df['Smoking Status']\n",
    "\n",
    "# ‚úÖ 7Ô∏è‚É£ Select Features & Target\n",
    "selected_features = ['Age', 'BMI', 'Smoking Status', 'Hypertension', 'Employment Type', \n",
    "                     'Savings Amount', 'Policy Type', 'Policy Renewal Status', 'Hospital Visits Per Year', \n",
    "                     'BMI_Smoker_Interaction']\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df['Insurance Cost']  # ‚úÖ Corrected from 'Target' to 'Insurance Cost'\n",
    "\n",
    "# ‚úÖ 8Ô∏è‚É£ Normalize Data (Scaling)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ‚úÖ 9Ô∏è‚É£ Train-Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ‚úÖ üîü Build Deep Learning Model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Linear activation for regression\n",
    "])\n",
    "\n",
    "# ‚úÖ 1Ô∏è‚É£1Ô∏è‚É£ Compile Model with Huber Loss (Handles Outliers)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='huber_loss',\n",
    "              metrics=['mae'])\n",
    "\n",
    "# ‚úÖ 1Ô∏è‚É£2Ô∏è‚É£ Train Model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ‚úÖ 1Ô∏è‚É£3Ô∏è‚É£ Plot Training Loss\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (Huber)\")\n",
    "plt.title(\"Deep Learning Model Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ‚úÖ 1Ô∏è‚É£4Ô∏è‚É£ Model Evaluation\n",
    "val_loss, val_mae = model.evaluate(X_val, y_val)\n",
    "print(f\"\\n‚úÖ Final Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in dataset: Index(['Name', 'Age', 'Gender', 'BMI', 'Smoking Status', 'Region', 'Diabetes',\n",
      "       'Hypertension', 'Heart Disease', 'Cancer History', 'Stroke',\n",
      "       'Liver Disease', 'Kidney Disease', 'COPD', 'TB', 'HIV/AIDS',\n",
      "       'Alcohol Consumption', 'Exercise Frequency', 'Diet Type',\n",
      "       'Stress Level', 'Medical History Score', 'Annual Income',\n",
      "       'Employment Type', 'Credit Score', 'Savings Amount',\n",
      "       'Number of Dependents', 'Previous Insurance Claims', 'Policy Type',\n",
      "       'Policy Renewal Status', 'Hospital Visits Per Year',\n",
      "       'Medication Costs Per Year', 'Insurance Cost', 'BMI Smoker',\n",
      "       'Income Dependents', 'BMI_Smoker_Interaction'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Available columns in dataset:\", df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
